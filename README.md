#Team Name: Level 2

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

### FAR VISION:
The tool or Wordpess plugin gives real-time update on the sales ranks of a list of books/market against your selected books, and traffic for prospective content. Use of the app is for competitive analysis so authors may determine which books sell well, and how their own book is doing comparatively. The app will also allow authors to see what potential readers are searching for to develop and market content accordingly. The app may also compare other author's website traffic or online "buzz", for example using comparative search hits from Alexa, comments and ratings from Amazon, and mentions across the web. We aim to pull data and resuls from Amazon, Barnes and Noble, GoodReads, Google, Alexa, Bing, Yahoo, and others. 

### NEAR VISION 
Prototype of the dashboard, live on a wordpress site, and conforms to a WP plug in guidelines 
-	Author facing dashboard
-	Pull data at least from Amazon.com for data
-	Customer facing options (shows to reader) – status and metrics against selected books, as permissioned by author

### STAKEHOLDERS
* Authors – who want know their competitive position for a book listed on Amazon
* Readers – who want to know how popular a book is
* Editors of the blog – deciding what content to post by popularity of existing books, or to choose books to feature for posts.
* Publishers – that want to know the popularity of content, success metrics, and to share books 
	
### URL of Backlog via Trello: 
* https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool

### REAL STAKEHOLDERS: 
* Geri Walton, Author, www.geriwalton.com, 
* Richard Kasperowski

### DETAIL PERSONA OF REAL STAKEHOLDER:
Geri Walton has long been fascinated by history and the people who create it. As a child growing up in a large family in Utah, she loved to sit around in a big circle with family members, sharing stories. Her father’s many stories—from not only his own childhood but the lives of their ancestor’s—particularly fascinated her.

After a long career in technical writing and publishing in the computer industry, Geri returned to history as her first love. She worked on several different books, articles, and blog ideas before realizing her passion was around the history and people of the 1700s and 1800s. So, she started her current blog in 2013.

Geri lives in Northern California with her husband, son, and two Pomeranians. When she’s not writing, she enjoys reading, cooking, and jogging. She is also a bit of a health nut. Geri graduated summa cum laude with BA in History from San Jose State University.
via: https://www.geriwalton.com/about/

Geri would like the ability to see how her book is doing compared with other books, wants to understand the book market, and see how her competitors/other authors are doing in regards to search traffic, website rankings, and other relevant metrics.

### FICTIONAL PERSONA WANTS:
Authors:
Authors want the ability to see how their book is doing, determine the best content to write about, and see how the market is evolving in their space.

Readers:
Readers want to know the most popular content, see how books rank, and learn about new subjects and content relevant to their interests.

Editors:
Blog editors want to be able to drive traffic, publish new content, and see new sources of books/content for ideas to publish on their blogs.

Publishers:
Publishers want to get an understanding of the market, see how categories of books are performing, and get an idea as to how their authors/books perform.

### Product Backlog Item (PBI) Story Points:
- Story Points were estimated based on judgements of effort and difficulty
- The entire team is considered a part of the developement team, as such, only developers were involved in the Story Point estimates
- We used the app Planning Poker online on the evening of 10/29 to estimate PBI points - points ranged from 3-34 points per Backlog Item.

### Rationale for ordering backlog:
We ordered our backlog based on the user use case (Authors first), then data source (Amazon first), and complexity/dependency (sub-groups are dependent features that first require another use case to be fully developed, in order to function properly).

### Definition of Ready 
- Stakeholder defined
- Includes the specific outlines of the feature
- User story includes the reason or purpose for the feature
- Must determine the data source (if applicable) for the feature
- PBI story points estimated via Planning Poker by the team
- Must understand the dependency of the feature with other user stories (sub-groups).


#README - Project Part 2 of 4

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

## Website and App:
Our website is hosted and available at: http://bookbeatapp.com

Our app, is currently at: http://bookbeatapp.com/book-beat/

##Topics:

###Points Forecast -
Our user stories originally ranged from 3-34 Points. We forecast that we can do upwards of 7 story points 
per sprint. Hence, we will break down future user stories into additional stories of smaller sizes as we work on them in the 
Sprint backlog for future sprints.

###Rationale for Forecast:
Our rationale for how many points we can complete in a 2 week sprint, comes from our discussion of the complexity 
of the work, and what we feel it would take to coordinate per sprint. 

###Stories into Sprint Backlog
We've since broken down a user story to 2 stories of 3 points each (total of 6 points, less than the 7 forecast), and brought it into our Backlog. 
As well, all stories in the backlog are less than 50% of the forecast velocity we have set.

###Stories into Tasks
We've begun turning those stories into Tasks using a Trello list, and assigning responsibility for each.

In order to develop and work, using BDD and TDD, we've designed simple behaviors and tests, to drive incremental development and completion of the tasks.

##Schedule:
(Playlist of all recordings we were able to save (parts of some meetings) are here: https://www.youtube.com/playlist?list=PLdSVN_Vqb9vonx5MU92msyQuFC5-4WME6)

###Sprint Planning:
Saturday 11/5 at 1:30 PM EST - Scheduled 1 hour, continued for ~2 hours.
(Recording unfortunately did not save for this meeting, size limit)

###Mob Programming
Monday 11/7 at 5:30 PM EST (Scheduled 1-2 hours)
-> https://www.youtube.com/watch?v=g_dy4aB6cjQ&feature=youtu.be 

###Daily Scrum(s)
Wednesday 11/9 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=GuUH-S_b5dM&feature=youtu.be

Friday 11/11 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=wN8hXUVXbqI&feature=youtu.be

Saturday (+2nd Mob/Pair Programming) 11/12 at 2:30 pm EST (half hour daily scrum + 2 hours programming)
-> https://www.youtube.com/watch?v=wj0FurIEm5E&feature=youtu.be

At the start of each daily scrum or programming meeting, we discussed what we did in the last 24 hours, and the work we'd do for the next 24 hours.

###Sprint Review:
Sunday 11/13 at 12:30 PM EST (Included the actual Stakeholder, Geri, and we went over the project, website, working software, and vision to gain feedback)
-> https://www.youtube.com/watch?v=3vTG1kJmgao&feature=youtu.be

###TDD and BDD:
We designed all the increments of the software and the programming in a BDD and TDD manner. We developed features and tests (in the Github) that were automated unit tests for our working piece of software, we also kept an excel for a test plan that helped us aggregate the tests within Dropbox (file "CSCI_E71_Part2-Test_Plan").

Proof of features: https://github.com/locustking/Level_2/tree/master/features

Proof of our tests / unit tests: https://github.com/locustking/Level_2/blob/master/bdd_output.txt 
(Also, under the Excel in Dropbox link labeled "CSCI_E71_Part2-Test_Plan"

Implementation can be found here: https://github.com/locustking/Level_2/tree/master/features/bootstrap

##URL of Backlog via Trello 
###(Contains Backlog, Sprint Backlog, User Stories, Tasks, Timeline, and more):
    https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool

The Trello board also contains the Sprint Burndown chart (both link, and an image file).

##Product Files - Listing breakdowns, files, personas, minutes, screenshots + recordings of some meetings):
     https://www.dropbox.com/sh/0dt5bp4taqr8qzu/AAC17L79iNsP6t0wipnTAUnQa?dl=0 

These also include minutes for all meetings, in which we checked in and reviewed the work over the prior 24 hours, the next 24 hours, and any impediments.

#README - Project Part 3 of 4

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

## Website and App:
Our website is hosted and available at: http://bookbeatapp.com

Our app, is currently at: http://bookbeatapp.com/book-beat/

##Topics:

###Continuous Integration/Continuous Delivery:

Our CI/CD tool of choice is Jenkins
It is hosted at http://www.bookbeatjenkins.com  

There are three jobs setup to support our CI/CD pipeline.  They are as follows:

- bookbeat
- bookbeat-prod-deploy
- bookbeat-stage-deploy

Each commit to the master branch of our Level_2.git repository master branch triggers the 'bookbeat' build job.  This job
runs our test suite for our BDD and TDD test cases.  If the tests pass successfully, it triggers the bookbeat-stage-deploy job.
This pushes the files to our bookbeat app staging environment.  Once the team verifies the staging site looks good, a manual run 
of the bookbeat-prod-deploy will push our code to our production environment.

To see our Jenkins setup, go to the above mentioned URL and supply the following credentials:

- username: testuser
- password: 1password

Screencast - xxxxxxxxxxxxxx

###BDD and TDD:
The third of 4 sprints of development we continued to use Behat Cucumber.
We used a behavior driven development method. Features and automated tests were developed before coding the application. Evidence of this can be seen in the Pair and Mob programming recordings for this sprint: https://www.youtube.com/playlist?list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2

3 new behavioral features BB3, BB4, and BB5 were added in this sprint. The new features resulted in 19 new unit tests. Including the previous sprint, there are 31 total unit tests that are passing with no failures.

Currently there are 5 defined Cucumber features are located:
https://github.com/locustking/Level_2/tree/master/features
Behat Cucumber testing output is located:
https://github.com/locustking/Level_2/blob/master/bdd_output.txt

