#Team Name: Level 2

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica T Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

### FAR VISION:
The tool or Wordpess plugin gives real-time update on the sales ranks of a list of books/market against your selected books, and traffic for prospective content. Use of the app is for competitive analysis so authors may determine which books sell well, and how their own book is doing comparatively. The app will also allow authors to see what potential readers are searching for to develop and market content accordingly. The app may also compare other author's website traffic or online "buzz", for example using comparative search hits from Alexa, comments and ratings from Amazon, and mentions across the web. We aim to pull data and resuls from Amazon, Barnes and Noble, GoodReads, Google, Alexa, Bing, Yahoo, and others. 

### NEAR VISION 
Prototype of the dashboard, live on a wordpress site, and conforms to a WP plug in guidelines 
-	Author facing dashboard
-	Pull data at least from Amazon.com for data
-	Customer facing options (shows to reader) – status and metrics against selected books, as permissioned by author

### STAKEHOLDERS
* Authors – who want know their competitive position for a book listed on Amazon
* Readers – who want to know how popular a book is
* Editors of the blog – deciding what content to post by popularity of existing books, or to choose books to feature for posts.
* Publishers – that want to know the popularity of content, success metrics, and to share books 
	
### URL of Backlog via Trello: 
* https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool

### REAL STAKEHOLDERS: 
* Geri Walton, Author, www.geriwalton.com, 
* Richard Kasperowski

### DETAIL PERSONA OF REAL STAKEHOLDER:
Geri Walton has long been fascinated by history and the people who create it. As a child growing up in a large family in Utah, she loved to sit around in a big circle with family members, sharing stories. Her father’s many stories—from not only his own childhood but the lives of their ancestor’s—particularly fascinated her.

After a long career in technical writing and publishing in the computer industry, Geri returned to history as her first love. She worked on several different books, articles, and blog ideas before realizing her passion was around the history and people of the 1700s and 1800s. So, she started her current blog in 2013.

Geri lives in Northern California with her husband, son, and two Pomeranians. When she’s not writing, she enjoys reading, cooking, and jogging. She is also a bit of a health nut. Geri graduated summa cum laude with BA in History from San Jose State University.
via: https://www.geriwalton.com/about/

Geri would like the ability to see how her book is doing compared with other books, wants to understand the book market, and see how her competitors/other authors are doing in regards to search traffic, website rankings, and other relevant metrics.

### FICTIONAL PERSONA WANTS:
Authors:
Authors want the ability to see how their book is doing, determine the best content to write about, and see how the market is evolving in their space.

Readers:
Readers want to know the most popular content, see how books rank, and learn about new subjects and content relevant to their interests.

Editors:
Blog editors want to be able to drive traffic, publish new content, and see new sources of books/content for ideas to publish on their blogs.

Publishers:
Publishers want to get an understanding of the market, see how categories of books are performing, and get an idea as to how their authors/books perform.

### Product Backlog Item (PBI) Story Points:
- Story Points were estimated based on judgements of effort and difficulty
- The entire team is considered a part of the developement team, as such, only developers were involved in the Story Point estimates
- We used the app Planning Poker online on the evening of 10/29 to estimate PBI points - points ranged from 3-34 points per Backlog Item.

### Rationale for ordering backlog:
We ordered our backlog based on the user use case (Authors first), then data source (Amazon first), and complexity/dependency (sub-groups are dependent features that first require another use case to be fully developed, in order to function properly).

### Definition of Ready 
- Stakeholder defined
- Includes the specific outlines of the feature
- User story includes the reason or purpose for the feature
- Must determine the data source (if applicable) for the feature
- PBI story points estimated via Planning Poker by the team
- Must understand the dependency of the feature with other user stories (sub-groups).


#README - Project Part 2 of 4

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

## Website and App:
Our website is hosted and available at: http://bookbeatapp.com

Our app, is currently at: http://bookbeatapp.com/book-beat/

##Topics:

###Points Forecast -
Our user stories originally ranged from 3-34 Points. We forecast that we can do upwards of 7 story points 
per sprint. Hence, we will break down future user stories into additional stories of smaller sizes as we work on them in the 
Sprint backlog for future sprints.

###Rationale for Forecast:
Our rationale for how many points we can complete in a 2 week sprint, comes from our discussion of the complexity 
of the work, and what we feel it would take to coordinate per sprint. 

###Stories into Sprint Backlog
We've since broken down a user story to 2 stories of 3 points each (total of 6 points, less than the 7 forecast), and brought it into our Backlog. 
As well, all stories in the backlog are less than 50% of the forecast velocity we have set.

###Stories into Tasks
We've begun turning those stories into Tasks using a Trello list, and assigning responsibility for each.

In order to develop and work, using BDD and TDD, we've designed simple behaviors and tests, to drive incremental development and completion of the tasks.

##Schedule:
(Playlist of all recordings we were able to save (parts of some meetings) are here: https://www.youtube.com/playlist?list=PLdSVN_Vqb9vonx5MU92msyQuFC5-4WME6)

###Sprint Planning:
Saturday 11/5 at 1:30 PM EST - Scheduled 1 hour, continued for ~2 hours.
(Recording unfortunately did not save for this meeting, size limit)

###Mob Programming
Monday 11/7 at 5:30 PM EST (Scheduled 1-2 hours)
-> https://www.youtube.com/watch?v=g_dy4aB6cjQ&feature=youtu.be 

###Daily Scrum(s)
Wednesday 11/9 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=GuUH-S_b5dM&feature=youtu.be

Friday 11/11 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=wN8hXUVXbqI&feature=youtu.be

Saturday (+2nd Mob/Pair Programming) 11/12 at 2:30 pm EST (half hour daily scrum + 2 hours programming)
-> https://www.youtube.com/watch?v=wj0FurIEm5E&feature=youtu.be

At the start of each daily scrum or programming meeting, we discussed what we did in the last 24 hours, and the work we'd do for the next 24 hours.

###Sprint Review:
Sunday 11/13 at 12:30 PM EST (Included the actual Stakeholder, Geri, and we went over the project, website, working software, and vision to gain feedback)
-> https://www.youtube.com/watch?v=3vTG1kJmgao&feature=youtu.be

###TDD and BDD:
We designed all the increments of the software and the programming in a BDD and TDD manner. We developed features and tests (in the Github) that were automated unit tests for our working piece of software, we also kept an excel for a test plan that helped us aggregate the tests within Dropbox (file "CSCI_E71_Part2-Test_Plan").

Proof of features: https://github.com/locustking/Level_2/tree/master/features

Proof of our tests / unit tests: https://github.com/locustking/Level_2/blob/master/bdd_output.txt 
(Also, under the Excel in Dropbox link labeled "CSCI_E71_Part2-Test_Plan"

Implementation can be found here: https://github.com/locustking/Level_2/tree/master/features/bootstrap

##URL of Backlog via Trello 
###(Contains Backlog, Sprint Backlog, User Stories, Tasks, Timeline, and more):
    https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool

The Trello board also contains the Sprint Burndown chart (both link, and an image file).

##Product Files - Listing breakdowns, files, personas, minutes, screenshots + recordings of some meetings):
     https://www.dropbox.com/sh/0dt5bp4taqr8qzu/AAC17L79iNsP6t0wipnTAUnQa?dl=0 

These also include minutes for all meetings, in which we checked in and reviewed the work over the prior 24 hours, the next 24 hours, and any impediments.

#README - Project Part 3 of 4

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

## Website and App:
Our website is hosted and available at: http://bookbeatapp.com

Our app, is currently at: http://bookbeatapp.com/book-beat/

##Topics:

###Points Forecast -
Our last sprint, we believed we could do 7 story points. After a review, we decided we could do over 27 points this sprint, and began to look at some of our existing stories to break them down into tasks. We aimed to allow the Author to input into the software using ISBN numbers to pull relevant data.

###Rationale for Forecast:
Our rationale for how many points we can complete in this 2 week sprint came from the fact that we had a lot of missing pieces setup, and believed we had the right environment to take on more story points.

###Stories into Sprint Backlog
As such, we aimed for a maximum of 13 story points per user story this sprint (less than 50% of the sprint velocity), and did the user stories (BB3 - 8 Points, BB4 - 13 Points, and BB5 - 3 points for a combined 24 points). These stories would allow us to take Author's input and rank and sort results for books.

###Stories into Tasks
We've begun turning those stories into Tasks using a Trello list, and assigning responsibility for each.

In order to develop and work, using BDD and TDD, we've designed simple behaviors and tests, to drive incremental development and completion of the tasks. We also integrated a CD/CI framework using Jenkins.

##Schedule:
Playlist of all recordings we were able to save from this Sprint 3 of 4 Sessions are here (also in Schedule List in Trello): https://www.youtube.com/playlist?list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2

###Sprint Planning:
Saturday 11/19 at 2:30 PM EST - Scheduled 1 hour, continued for ~2 hours.
https://www.youtube.com/watch?v=TppQPD8VdR0&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=1

We decided on the sprint planning to take on the ability to have authors submit book lists (via a file first) that would help the authors choose a variety of books to compare and sort via the Amazon API.

###Mob and Pair Programming
Monday 11/21 at 7:30 PM EST Pair Programming (Scheduled 1-2 hours)
-> https://www.youtube.com/watch?v=jYDtdfTB1eM&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=2

Wednesday 11/23 Mob Programming here (Scheduled 1-2 hours):
-> https://www.youtube.com/watch?v=gT2BYKgHqpY&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=4

###Daily Scrum(s)
Tuesday 11/21 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=3EQr8aAdW2Q

Friday 11/24 at 12 PM EST (half hour)
-> https://www.youtube.com/watch?v=NFQicYXdj74&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=5

Saturday (+2nd Mob/Pair Programming) 11/26 at 12:30 pm EST (half hour daily scrum + programming)
-> https://www.youtube.com/watch?v=UCTXRxKN5hE&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=6

At the start of each daily scrum or programming meeting, we discussed what we did in the last 24 hours, and the work we'd do for the next 24 hours.

We didn't face major impediments in our work, with the exception of the Thanksgiving holiday. This forced us to consider planning ahead of holiday weekends, to avoid scheduling problems.

###Sprint Review:
Sunday 11/27 at 11:30 PM EST (Included the actual Stakeholder, Geri, and we went over the project, new website, updated working software, and vision to gain feedback)
-> https://www.youtube.com/watch?v=79lKKMbkG8A&list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2&index=7

Geri noted she wanted to see inputs from other countries (like the UK), and gave suggestions which we'll use to order the backlog (submitting files, etc.). We also spoke as a team, and came up with a new tip we'll use for future sprints which is to have the Sprint Planning session earlier in order to give more time to development.

###Continuous Integration/Continuous Delivery:

Our CI/CD tool of choice is Jenkins
It is hosted at http://www.bookbeatjenkins.com  

There are three jobs setup to support our CI/CD pipeline.  They are as follows:

- bookbeat
- bookbeat-prod-deploy
- bookbeat-stage-deploy

Each commit to the master branch of our Level_2.git repository master branch triggers the 'bookbeat' build job.  This job
runs our test suite for our BDD and TDD test cases.  If the tests pass successfully, it triggers the bookbeat-stage-deploy job.
This pushes the files to our bookbeat app staging environment.  Once the team verifies the staging site looks good, a manual run 
of the bookbeat-prod-deploy will push our code to our production environment.

To see our Jenkins setup, go to the above mentioned URL and supply the following credentials:

- username: testuser
- password: 1password

Screencast - https://www.dropbox.com/home/Level-2_CSCI-E71-Project/Meeting%20Notes%20%2B%20Recordings/ci_cd-screencast.mov

###BDD and TDD:
The third of 4 sprints of development we continued to use Behat Cucumber.
We used a behavior driven development method. Features and automated tests were developed before coding the application. Evidence of this can be seen in the Pair and Mob programming recordings for this sprint: https://www.youtube.com/playlist?list=PLdSVN_Vqb9vpJtJ4-UMkpSDz_aOFoHGf2

3 new behavioral features BB3, BB4, and BB5 were added in this sprint. The new features resulted in 19 new unit tests. Including the previous sprint, there are 31 total unit tests that are passing with no failures.

Currently there are 5 defined Cucumber features are located:
https://github.com/locustking/Level_2/tree/master/features
Behat Cucumber testing output is located:
https://github.com/locustking/Level_2/blob/master/bdd_output.txt

##URL of Backlog via Trello 
###(Contains Backlog, Sprint Backlog, User Stories, Tasks, Timeline, and more):
    https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool

The Trello board also contains the Sprint Burndown chart (both link, and an image file).

##Product Files - Listing breakdowns, files, personas, minutes, screenshots + recordings of some meetings):
     https://www.dropbox.com/sh/0dt5bp4taqr8qzu/AAC17L79iNsP6t0wipnTAUnQa?dl=0 

These also include minutes for all meetings, in which we checked in and reviewed the work over the prior 24 hours, the next 24 hours, and any impediments.

#README - Project Part 4 of 4

## OPEN SOURCE PRODUCT NAME: 
* Book Beat *(Book Author’s Competitive Analysis Tool)*

## Team Members: 
* Erica Abernathy
* Kaushik Bhatta
* Daryl Greer
* Doug Walton
* Basuki Winoto

### Roles:
* Scrum Master: Doug Walton
* Product Owner: Kaushik Bhatta
* Developers/Development Team: The entire team

## Website and App:
Our website is hosted and available at: http://bookbeatapp.com
Our app, is currently at: http://bookbeatapp.com/book-beat/
Staging environments included: staging1.bookbeatapp.com + staging2.bookbeatapp.com
##Topics:
###Points Forecast + Rationale for Forecast-
Our last sprint, we believed we were able to do over 27 points. One major change for us, that we decided on was bringing the Sprint Planning session earlier and that allowed us to pick up speed. Now that we had the CI/CD platform integrated, we decided to aim for 47 points. We felt we could pick up momentum from where we had left off.
###Stories into Sprint Backlog
As such, we aimed for a maximum of 23 story points per user story this sprint (less than 50% of the sprint velocity), and did the user stories (BB6 - 13 Points, BB7 - 13 Points, and BB8 - 21 points for a combined 47 points).

 These stories would allow us to take Author's input via the website, added a search function embedded with multiple Amazon requests and also allowed us to edit books and compare results between Amazon US and Amazon UK.

###Stories into Tasks
We turned those stories into Tasks using a Trello list, and assigning responsibility for each. Many tasks required research in order to complete, as we were integrating with the Amazon UK site now.
In order to develop and work, using BDD and TDD, we've designed simple behaviors and tests, to drive incremental development and completion of the tasks. We continued to integrate a CD/CI framework using Jenkins, and tried our hand at also adding Selenium.

##Schedule:
Playlist of all recordings we were able to save from this Sprint 4 of 4 Sessions are here (also in Schedule List in Trello): https://www.youtube.com/playlist?list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9

###Sprint Planning:
Monday 11/28 at 7:30 PM EST (after class) - Scheduled 1 hour, continued for ~2 hours.
https://www.youtube.com/watch?v=8NCa6H48lnY&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=1 

We decided on the sprint planning to make the UI much more useable and allow the authors to submit content via the website.

###Pair Programming / Mob
Saturday 12/3 at 5 PM EST Pair Programming (Scheduled .5 - 1 hour), between Daryl and Doug
-> https://www.youtube.com/watch?v=OBTmLBiA8gQ&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=3 

Also, had another follow up same day: Code review Saturday 12/3 at 9 PM EST, no recording, between Daryl and Basuki.

Mob Programming + Selenium Test on 12/11 at 4 PM EST with Basuki and Erica (no recording)

Mob Programming and Troubleshooting: 12/10 at 8 PM EST with Basuki, Doug, and Erica (no recording)

###Daily Scrum(s)

At the start of each daily scrum or programming meeting, we discussed what we did in the last 24 hours, and the work we'd do for the next 24 hours.

The Scrum Master took note of the time, and kept us accountable.
We faced some major impediments – Daryl and KB got sick during the sprint, we needed research with Amazon UK, we had some blocks from Amazon’s API, the UK site also had additional issues. Impediments are listed in a separate list on Trello.

Tuesday 11/30 8 PM EST – We had a Daily Scrum, to check in and assign tasks (no recording)

Friday 12/2 at 12 PM EST – Daily Scrum 
-> https://www.youtube.com/watch?v=c4rKlVwBcOc&index=2&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9 (Recording via Daryl)

Sunday 12/4 Scrum at 12 PM EST
-> https://www.youtube.com/watch?v=wVoIl2iMcE8&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=4 (Recording via Daryl)

Tuesday 12/6 12 PM EST (No recording)

Friday 12/9 12 PM EST 
-> https://www.youtube.com/watch?v=ZFCyAcDh5I0&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=5 (Recording via Daryl)

Saturday 12/10 12 PM EST:
-> https://www.youtube.com/watch?v=Eov7NRgC1WI&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=6 

Sunday – Daily Scrum and Review 12/11 12 PM EST:
-> https://www.youtube.com/watch?v=UbkCFtqG8j8&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=7 (Recording via Daryl)

###Sprint Review with Stakeholder:
Sunday 12/11 at 4 PM EST (Included the actual Stakeholder, Geri, and we went over the project, new code and databases, updated working software, and vision to gain feedback)

Review with Stakeholder is here: https://www.dropbox.com/personal/Level-2_CSCI-E71-Project/Meeting%20Notes%20%2B%20Recordings/2016-12-11%201Sprint%20Review%20with%20Stakeholder (Saved via Ringcentral Meetings)

Geri noted she liked the new website, the search function and prepopulated results. She noted, on future releases she would want to work on new data feeds (like Goodreads) and also get new columns – like Date of Publication, Publisher, etc.

###Sprint Review with Demo/Rehearsal:
Monday 12/12 at 3 PM EST: (Recording to be available 12/13)

We did a Product Demo run through, and Sprint Review. 

The Product Owner noted how grateful he was for the team effort, and noted the changes for future versions based on the Stakeholder feedback, and their work so far (Good reads, and new columns – Publisher, Published Date). We also went over the improvements we could made for future sprints.

Monday 12/12 at 5:30 PM EST: (In Class)
- In class review of the Software

###Continuous Integration/Continuous Delivery:
Our CI/CD tool of choice is Jenkins
It is hosted at http://www.bookbeatjenkins.com  
There are three jobs setup to support our CI/CD pipeline.  They are as follows:
- bookbeat
- bookbeat-prod-deploy
- bookbeat-stage-deploy

We also have staging areas: staging1.bookbeatapp.com + staging2.bookbeatapp.com 

Each commit to the master branch of our Level_2.git repository master branch triggers the 'bookbeat' build job.  This job runs our test suite for our BDD and TDD test cases.  If the tests pass successfully, it triggers the bookbeat-stage-deploy job.

This pushes the files to our bookbeat app staging environment.  Once the team verifies the staging site looks good, a manual run of the bookbeat-prod-deploy will push our code to our production environment.

To see our Jenkins setup, go to the above mentioned URL and supply the following credentials:

- username: testuser
- password: 1password

Prior Screencast - https://www.dropbox.com/home/Level-2_CSCI-E71-Project/Meeting%20Notes%20%2B%20Recordings/ci_cd-screencast.mov

We also integrated Selenium in order to develop test cases for the UI and website for staging.

###BDD and TDD:
The fourth of 4 sprints of development we continued to use Behat Cucumber. We used a behavior driven development method. Features and automated tests were developed before coding the application. 

Evidence of this can be seen in the Pair and Mob programming recordings for this sprint: https://www.youtube.com/watch?v=OBTmLBiA8gQ&list=PLdSVN_Vqb9vqvCZk70RdhUglwB6wiBn-9&index=3 

3 new user stories + features for BB6, BB7, and BB8 were added in this sprint. The new features resulted in 101 new unit tests in total. The previous sprint, there were 41 total unit tests that were passing with no failures.

You can view these here:  https://github.com/locustking/Level_2/blob/master/bdd_output.txt 

Currently there are defined Cucumber features are located: https://github.com/locustking/Level_2/tree/master/features 
Behat Cucumber testing output is located: https://github.com/locustking/Level_2/blob/master/bdd_output.txt 

Selenium was also integrated for our UI: https://github.com/locustking/Level_2/blob/master/vendor/phpunit/phpunit-selenium/Tests/selenium-tests.php 

We had several tests integrated for the UI and the product. This is available via the Jenkins login, and shown as jobs based on the integration between Selenium and Jenkins.

##URL of Backlog via Trello 
###(Contains Backlog, Sprint Backlog, User Stories, Tasks, Timeline, and more):
https://trello.com/b/qDwMkuI6/book-beat-a-book-author-s-competitive-analysis-tool 

The Trello board also contains the Sprint Burndown chart (both link, and an image file) for Sprint #4: https://trello-attachments.s3.amazonaws.com/58121fbf6125ce7c59069e82/584dc9216bcb8c105e1be77d/3c49591ae00b38003254730650254554/sprint_4_of_4_burndown_chart.png 

##Product Files - Listing breakdowns, files, personas, minutes, screenshots + recordings of some meetings):
 https://www.dropbox.com/sh/0dt5bp4taqr8qzu/AAC17L79iNsP6t0wipnTAUnQa?dl=0  

The Product Files also contains the Radiators used for the Personas we used during the sprint (https://www.dropbox.com/s/jpc6vw7ygf4bvb0/Book%20Beat%20App%20%E2%80%93%20Personas.pptx?dl=0 )and the Product vision was listed as a radiator on our site via http://bookbeatapp.com/our-vision/ 

## Future Sprints:

Based on our Stakeholder Feedback, we decided in future sprints to work on the Goodreads data and also add more columns of data based on our scraper.

Our sprint review with the development team came up with new suggestions for how to improve on future sprints. We concluded that we could benefit from:
-	Being able to see what others are working on in real time
-	Separate branches in Github / staging and production sites for the members involved to see the work contributed
-	Documentation around the code development (code commenting, or more version control), etc.

We faced some issues around version control we would like to address in future sprints, and the suggestions above could assist on that endeavor.
